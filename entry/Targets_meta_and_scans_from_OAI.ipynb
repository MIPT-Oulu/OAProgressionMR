{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "import seaborn as sns\n",
    "import pyreadstat\n",
    "\n",
    "from koafusion.datasets.oai import (prefix_var_to_visit_month,\n",
    "                                    release_to_visit_month,\n",
    "                                    side_code_to_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Read the meta info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_compose_asmts(fpaths, capitalize=False, verbose=False):\n",
    "    \"\"\" \"\"\"\n",
    "    if verbose:\n",
    "        print(fpaths)\n",
    "    dfs = []\n",
    "\n",
    "    for i, fpath in enumerate(fpaths):\n",
    "        if fpath.suffix in (\".csv\", \".txt\"):\n",
    "            df = pd.read_csv(fpath, sep='|', index_col=False)\n",
    "        elif fpath.suffix == \".sas7bdat\":\n",
    "            df, _ = pyreadstat.read_sas7bdat(fpath, user_missing=True)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported extension: {fpath.suffix}\")\n",
    "        \n",
    "        if capitalize:\n",
    "            # Capitalize all columns names\n",
    "            df.columns = df.columns.str.upper()\n",
    "\n",
    "        # Find release info\n",
    "        prefix_var = 'VXX'\n",
    "        for c in df.columns:\n",
    "            if re.match(\"V\\d\\d.*$\", c):\n",
    "                prefix_var = c[:3]\n",
    "                break\n",
    "        # Remove prefix from column names and add corresponding column\n",
    "        columns = []\n",
    "        for c in df.columns:\n",
    "            if c.startswith(prefix_var):\n",
    "                columns.append(c[3:])\n",
    "            else:\n",
    "                columns.append(c)\n",
    "        df.columns = columns\n",
    "        df.loc[:, 'PREFIX_VAR'] = prefix_var\n",
    "\n",
    "        if verbose:\n",
    "            print(f'df idx: {i} num: {len(df)}')\n",
    "        dfs.append(df)\n",
    "\n",
    "    if len(dfs) > 1:\n",
    "        out = pd.concat(dfs, axis=0)\n",
    "    else:\n",
    "        out = dfs[0]\n",
    "    if verbose:\n",
    "        print(f\"num total: {len(out)}\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def read_compose_contents(paths):\n",
    "    dfs = []\n",
    "    for p in paths:\n",
    "        df = pd.read_csv(p, index_col=False, sep=\",\",\n",
    "                         dtype={\"Folder\": str,\n",
    "                                \"ParticipantID\": str,\n",
    "                                \"StudyDate\": int,\n",
    "                                \"SeriesDescription\": str})\n",
    "        df.loc[:, \"visit_month\"] = [release_to_visit_month[e.split(\"/\")[0]]\n",
    "                                    for e in df[\"Folder\"].tolist()]\n",
    "        df.loc[:, \"visit\"] = [int(p[:-1]) for p in df[\"visit_month\"].tolist()]\n",
    "        \n",
    "        df = df.rename(columns={\"ParticipantID\": \"patient\"})\n",
    "        \n",
    "        dfs.append(df)\n",
    "    out = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "    return out\n",
    "\n",
    "\n",
    "def preproc_contents(df):\n",
    "    # Preprocess imaging inventory for easier merging\n",
    "    df_t = df.copy()\n",
    "    df_t[\"sequence\"] = \"\"\n",
    "    df_t[\"side\"] = \"\"\n",
    "    \n",
    "    mapping = {\n",
    "        # series_in: (series_out, side)\n",
    "        'MP_LOCATOR_LEFT': ('MP_LOCATOR', \"LEFT\"),\n",
    "        'MP_LOCATOR_RIGHT': ('MP_LOCATOR', \"RIGHT\"),\n",
    "        'COR_IW_TSE_LEFT': ('COR_IW_TSE', \"LEFT\"),\n",
    "        'COR_IW_TSE_RIGHT': ('COR_IW_TSE', \"RIGHT\"),\n",
    "        'PA Fixed Flexion Left Knee': ('PA Fixed Flexion Knee', \"LEFT\"),\n",
    "        'PA Fixed Flexion Right Knee': ('PA Fixed Flexion Knee', \"RIGHT\"),\n",
    "        'SAG_T2_CALC_LEFT': ('SAG_T2_CALC', \"LEFT\"),\n",
    "        'SAG_T2_CALC_RIGHT': ('SAG_T2_CALC', \"RIGHT\"),\n",
    "        'SAG_3D_DESS_LEFT': ('SAG_3D_DESS', \"LEFT\"),\n",
    "        'SAG_3D_DESS_RIGHT': ('SAG_3D_DESS', \"RIGHT\"),\n",
    "        'COR_MPR_LEFT': ('COR_MPR', \"LEFT\"),\n",
    "        'COR_MPR_RIGHT': ('COR_MPR', \"RIGHT\"),\n",
    "        'AX_MPR_LEFT': ('AX_MPR', \"LEFT\"),\n",
    "        'AX_MPR_RIGHT': ('AX_MPR', \"RIGHT\"),\n",
    "        'SAG_IW_TSE_LEFT': ('SAG_IW_TSE', \"LEFT\"),\n",
    "        'SAG_IW_TSE_RIGHT': ('SAG_IW_TSE', \"RIGHT\"),\n",
    "        'COR_T1_3D_FLASH_LEFT': ('COR_T1_3D_FLASH', \"LEFT\"),\n",
    "        'COR_T1_3D_FLASH_RIGHT': ('COR_T1_3D_FLASH', \"RIGHT\"),\n",
    "        'SAG_T2_MAP_LEFT': ('SAG_T2_MAP', \"LEFT\"),\n",
    "        'SAG_T2_MAP_RIGHT': ('SAG_T2_MAP', \"RIGHT\"),\n",
    "        'Bilateral PA Fixed Flexion Knee': ('Bilateral PA Fixed Flexion Knee', \"OTHER\"),\n",
    "        'Full Limb': ('Full Limb', \"OTHER\"),\n",
    "        'MP_LOCATOR_THIGH': ('MP_LOCATOR_THIGH', \"OTHER\"),\n",
    "        'AX_T1_THIGH': ('AX_T1_THIGH', \"OTHER\"),\n",
    "        'PRESCRIPTION_THIGH': ('PRESCRIPTION_THIGH', \"OTHER\"),\n",
    "        'Lateral Left Knee': ('Lateral Knee', \"LEFT\"),\n",
    "        'Lateral Right Knee': ('Lateral Knee', \"RIGHT\"),\n",
    "        'AP Pelvis': ('AP Pelvis', \"OTHER\"),\n",
    "        'PA Left Hand': ('PA Hand', \"LEFT\"),\n",
    "        'PA Right Hand': ('PA Hand', \"RIGHT\"),\n",
    "        'PA Bilateral Hand': ('PA Bilateral Hand', \"OTHER\"),\n",
    "        'OTHER': ('OTHER', \"OTHER\"),\n",
    "    }\n",
    "\n",
    "    df_proc = df_t.assign(\n",
    "        sequence=lambda x: [mapping[e][0] for e in x[\"SeriesDescription\"].tolist()],\n",
    "        side=lambda x: [mapping[e][1] for e in x[\"SeriesDescription\"].tolist()]\n",
    "    )\n",
    "    return df_proc\n",
    "\n",
    "\n",
    "dir_contents = Path(\"ACT:SET_PATH/contents\")\n",
    "paths_contents = dir_contents.glob(\"*.csv\")\n",
    "\n",
    "df_contents = read_compose_contents(paths_contents)\n",
    "display(df_contents.head())\n",
    "\n",
    "df_contents_proc = preproc_contents(df_contents)\n",
    "display(df_contents_proc.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def read_compose_clinical(paths):\n",
    "    df = read_compose_asmts(paths)\n",
    "\n",
    "    df.columns = df.columns.str.upper()\n",
    "    df = df.rename(columns={\"ID\": \"patient\", })\n",
    "    \n",
    "    df = df.astype({\"patient\": str})\n",
    "    \n",
    "    df.loc[:, \"visit_month\"] = [prefix_var_to_visit_month[p]\n",
    "                                for p in df[\"PREFIX_VAR\"].tolist()]\n",
    "    df.loc[:, \"visit\"] = [int(p[:-1]) for p in df[\"visit_month\"].tolist()]\n",
    "\n",
    "    sel = [\n",
    "        \"patient\", \"PREFIX_VAR\", \"visit_month\", \"visit\",\n",
    "        \"AGE\", \"P01BMI\", \"LKDEFCV\", \"RKDEFCV\",\n",
    "        \"P01INJR\", \"P01INJR1\", \"P01INJR2\", \"P01INJR3\", \n",
    "        \"P01KSURGR\", \"P01KRSR\", \"P01KRSRA\", \n",
    "        \"P01ARTR\", \"P01ARTR1\", \"P01ARTR2\", \"P01ARTR3\", \"P01ARTRINJ\", \n",
    "        \"P01MENR\", \"P01MENR1\", \"P01MENR2\", \"P01MENR3\", \"P01MENRINJ\", \n",
    "        \"P01LRR\", \"P01LRR1\", \"P01LRR2\", \"P01LRR3\", \"P01OTSURGR\",\n",
    "        \"P01OTSR1\", \"P01OTSR2\", \"P01OTSR3\", \"P01OTSRINJ\",\n",
    "        \"P01INJL\", \"P01INJL1\", \"P01INJL2\", \"P01INJL3\", \n",
    "        \"P01KSURGL\", \"P01KRSL\", \"P01KRSLA\", \n",
    "        \"P01ARTL\", \"P01ARTL1\", \"P01ARTL2\", \"P01ARTL3\", \"P01ARTLINJ\", \n",
    "        \"P01MENL\", \"P01MENL1\", \"P01MENL2\", \"P01MENL3\", \"P01MENLINJ\", \n",
    "        \"P01LRL\", \"P01LRL1\", \"P01LRL2\", \"P01LRL3\", \n",
    "        \"P01OTSURGL\", \"P01OTSL1\", \"P01OTSL2\", \"P01OTSL3\", \"P01OTSLINJ\", \n",
    "        \"P01RHBE\", \"P01LHBE\", \"RKPFCRE\", \"LKPFCRE\", \n",
    "        \"WSRKN1\", \"WSRKN2\", \"WSLKN1\", \"WSLKN2\", \n",
    "        \"KOOSYMR\", \"KOOSYML\", \"KOOSKPL\", \"KOOSKPR\",\n",
    "        \"KPA30CV\", \"KPACDCV\", \"KPACT30\", \"KPACTCV\", \"KPMED\", \"KPMEDCV\", \n",
    "        \"KPNL12\", \"KPNR12\", \"KPNL12M\", \"KPNR12M\", \"KPL12CV\", \"KPR12CV\", \n",
    "        \"KPL30CV\", \"KPR30CV\", \"KPRK20B\", \"KPLK20B\", \"KPLK20D\", \"KPRK20D\",\n",
    "        \"KPLKN1\", \"KPLKN2\", \"KPLKN3\", \"KPRKN1\", \"KPRKN2\", \"KPRKN3\",\n",
    "        \"MISSWK\", \"PMLKRCV\", \"PMRKRCV\", \"LKSX\", \"RKSX\",\n",
    "        \"WOMADLL\", \"WOMADLR\", \"WOMKPL\", \"WOMKPR\", \"WOMSTFL\", \"WOMSTFR\", \"WOMTSL\", \"WOMTSR\",  # WOMAC\n",
    "        \"WPLKN1\", \"WPLKN2\", \"WPLKN3\", \"WPLKN4\", \"WPLKN5\",\n",
    "        \"WPRKN1\", \"WPRKN2\", \"WPRKN3\", \"WPRKN4\", \"WPRKN5\",\n",
    "        \"P01SVLKOST\", \"P01SVRKOST\",\n",
    "        \"KRSR12\", \"KRSL12\",  # knee replacement since last visit, right and left\n",
    "    ]\n",
    "    df = df.loc[:, sel]\n",
    "    return df\n",
    "\n",
    "\n",
    "def print_unique(df, fields):\n",
    "    for field in fields:\n",
    "        print(field, pd.unique(df[field]))\n",
    "\n",
    "\n",
    "def preproc_clinical(df):\n",
    "    # Harmonize the values and fill the missing\n",
    "    for field in (\"PMLKRCV\", \"PMRKRCV\"):\n",
    "        dict_fix = {\n",
    "            np.nan: -1, ' ': -1,\n",
    "            '.: Missing Form/Incomplete Workbook': -1,\n",
    "            0.0: 0, '0': 0, '0: No pain': 0,\n",
    "            1.0: 1, '1': 1, '1: 1': 1,\n",
    "            2.0: 2, '2': 2, '2: 2': 2,\n",
    "            3.0: 3, '3': 3, '3: 3': 3,\n",
    "            4.0: 4, '4': 4, '4: 4': 4,\n",
    "            5.0: 5, '5': 5, '5: 5': 5,\n",
    "            6.0: 6, '6': 6, '6: 6': 6,\n",
    "            7.0: 7, '7': 7, '7: 7': 7,\n",
    "            8.0: 8, '8': 8, '8: 8': 8,\n",
    "            9.0: 9, '9': 9, '9: 9': 9,\n",
    "            10.0: 10, '10': 10, '10: Pain as bad as you can imagine': 10,\n",
    "        }\n",
    "        df = df.fillna({field: -1}, axis=0)\n",
    "        df = df.replace({field: dict_fix})\n",
    "\n",
    "    for field in (\"KPL30CV\", \"KPR30CV\", \"KRSL12\", \"KRSR12\",\n",
    "                  \"P01INJL\", \"P01INJR\", \"P01KSURGL\", \"P01KSURGR\",\n",
    "                  \"P01KRSL\", \"P01KRSR\",\n",
    "                  \"P01ARTL\", \"P01ARTR\", \"P01ARTLINJ\", \"P01ARTRINJ\",\n",
    "                  \"P01MENL\", \"P01MENR\", \"P01MENLINJ\", \"P01MENRINJ\",\n",
    "                  \"P01LRL\", \"P01LRR\",\n",
    "                  \"P01OTSURGL\", \"P01OTSURGR\", \"P01OTSLINJ\", \"P01OTSRINJ\",\n",
    "                 ):\n",
    "        dict_fix = {\n",
    "            '1: Yes': 1, 1.0: 1, '1': 1,\n",
    "            '0: No': 0, 0.0: 0, '0': 0,\n",
    "            '.: Missing Form/Incomplete Workbook': -1, ' ': -1, np.nan: -1,\n",
    "        }\n",
    "        df = df.fillna({field: -1}, axis=0)\n",
    "        df = df.replace({field: dict_fix})\n",
    "\n",
    "    for field in (\"WOMADLL\", \"WOMADLR\", \"WOMKPL\", \"WOMKPR\",\n",
    "                  \"WOMSTFL\", \"WOMSTFR\", \"WOMTSL\", \"WOMTSR\"):\n",
    "        df = df.replace({field: {\" \": -1, np.nan: -1}})\n",
    "        df = df.fillna({field: -1}, axis=0)\n",
    "        df = df.astype({field: float})\n",
    "        \n",
    "    # Normalize the value ranges\n",
    "    for field in (\"WOMKPL\", \"WOMKPR\"):  # WOMAC pain, range [-1, 0-20] -> [-1, 0-100]\n",
    "        df.loc[:, field] = df[field].apply(lambda x: x * 5 if x > 0 else x)\n",
    "\n",
    "    # Melt \"side\"-specific columns\n",
    "    df = pd.concat([df.assign(**{\"side\": \"LEFT\"}),\n",
    "                    df.assign(**{\"side\": \"RIGHT\"})],\n",
    "                    axis=\"index\",\n",
    "                    ignore_index=True)\n",
    "\n",
    "    for f_left, f_right, f_out in [\n",
    "        (\"PMLKRCV\", \"PMRKRCV\", \"PM-KRCV\"),\n",
    "        (\"KPL30CV\", \"KPR30CV\", \"KP-30CV\"),\n",
    "        \n",
    "        (\"WOMADLL\", \"WOMADLR\", \"WOMADL-\"),  # WOMAC physical disability, range [-1, 0-68]\n",
    "        (\"WOMKPL\", \"WOMKPR\", \"WOMKP-\"),  # WOMAC pain\n",
    "        (\"WOMSTFL\", \"WOMSTFR\", \"WOMSTF-\"),  # WOMAC stiffness, range [-1, 0-8]\n",
    "        (\"WOMTSL\", \"WOMTSR\", \"WOMTS-\"),  # WOMAC total score, range [-1, 0-96]\n",
    "        (\"KRSL12\", \"KRSR12\", \"KRS-12\"),  # knee replacement surgery\n",
    "        \n",
    "        (\"P01INJL\", \"P01INJR\", \"P01INJ-\"),  # injury with loss of ability to walk\n",
    "        (\"P01KSURGL\", \"P01KSURGR\", \"P01KSURG-\"),  # surgery or arthroscopy\n",
    "        (\"P01KRSL\", \"P01KRSR\", \"P01KRS-\"),  # part or whole joint replacement\n",
    "        \n",
    "        (\"P01ARTL\", \"P01ARTR\", \"P01ART-\"),  # arthroscopy\n",
    "        (\"P01ARTLINJ\", \"P01ARTRINJ\", \"P01ART-INJ\"),  # arthroscopy after injury\n",
    "        (\"P01MENL\", \"P01MENR\", \"P01MEN-\"),  # meniscectomy\n",
    "        (\"P01MENLINJ\", \"P01MENRINJ\", \"P01MEN-INJ\"),  # meniscectomy after injury\n",
    "\n",
    "        (\"P01LRL\", \"P01LRR\", \"P01LR-\"),  # ligament repair surgery\n",
    "        (\"P01OTSURGL\", \"P01OTSURGR\", \"P01OTSURG-\"),  # any other surgery\n",
    "        (\"P01OTSLINJ\", \"P01OTSRINJ\", \"P01OTS-INJ\"),  # any other surgery after injury\n",
    "    ]:\n",
    "        df = df.assign(**{f_out: \"\"})\n",
    "\n",
    "        df.loc[df[\"side\"] == \"LEFT\", f_out] = df[f_left]\n",
    "        df.loc[df[\"side\"] == \"RIGHT\", f_out] = df[f_right]\n",
    "\n",
    "        df = df.astype({f_out: df[f_left].dtype})\n",
    "        df = df.drop(columns=[f_left, f_right])\n",
    "    # ---\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "dir_clinical = Path(\"ACT:SET_PATH/OAI_CompleteData_ASCII\")\n",
    "paths_clinical = sorted(dir_clinical.glob(\"AllClinical??.txt\"))\n",
    "\n",
    "df_clinical = read_compose_clinical(paths_clinical)\n",
    "\n",
    "df_clinical = preproc_clinical(df_clinical)\n",
    "print(len(df_clinical))\n",
    "df_clinical.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def read_enrollees(path):\n",
    "    df = pd.read_csv(path, index_col=False, sep=\"|\", dtype={\"ID\": str, })\n",
    "\n",
    "    df = df.rename(columns={\"ID\": \"patient\"})\n",
    "\n",
    "    df = df.replace({\"P02SEX\": {\"1: Male\": \"MALE\", \"2: Female\": \"FEMALE\"}})\n",
    "    \n",
    "    sel = [\"patient\", \"P02SEX\", \"P02RACE\", \"V00SITE\"]\n",
    "    df = df.loc[:, sel]\n",
    "    return df\n",
    "\n",
    "\n",
    "dir_enrollees = Path(\"ACT:SET_PATH/OAI_CompleteData_ASCII\")\n",
    "paths_enrollees = Path(dir_enrollees, \"Enrollees.txt\")\n",
    "\n",
    "df_enrollees = read_enrollees(paths_enrollees)\n",
    "print(len(df_enrollees))\n",
    "df_enrollees.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def read_compose_xr_sq(paths):\n",
    "    df = read_compose_asmts(paths, capitalize=True)\n",
    "    \n",
    "    df = df.rename(columns={\"ID\": \"patient\",\n",
    "                            \"SIDE\": \"side\", })\n",
    "    \n",
    "    df = df.astype({\"patient\": str})\n",
    "    \n",
    "    df.loc[:, \"side\"] = [side_code_to_str[c] for c in df[\"side\"].tolist()]\n",
    "    df.loc[:, \"visit_month\"] = [prefix_var_to_visit_month[p]\n",
    "                                for p in df[\"PREFIX_VAR\"].tolist()]\n",
    "    df.loc[:, \"visit\"] = [int(p[:-1]) for p in df[\"visit_month\"].tolist()]\n",
    "    \n",
    "    sel = [\"patient\", \"side\", \"PREFIX_VAR\", \"visit_month\", \"visit\",\n",
    "           \"XRKL\",\n",
    "           \"XROSFL\", \"XROSFM\",  # osteophytes, femur (OARSI grades)\n",
    "           \"XROSTL\", \"XROSTM\",  # osteophytes, tibia (OARSI grades)\n",
    "           \"XRJSL\", \"XRJSM\",  # joint-space narrowing (OARSI grades)\n",
    "           \"XRSCFL\", \"XRSCFM\",  # sclerosis, femur (OARSI grades)\n",
    "           \"XRSCTL\", \"XRSCTM\",  # sclerosis, tibia (OARSI grades)\n",
    "           \"XRATTL\", \"XRATTM\",  # attrition (OARSI grades)\n",
    "          ]\n",
    "    df = df.loc[:, sel]\n",
    "    return df\n",
    "\n",
    "\n",
    "def preproc_xr_sq(df):\n",
    "    for field in (\"XRKL\", ):\n",
    "        #print(field, pd.unique(df[field]))\n",
    "        dict_fix = {\n",
    "            \"P\": 5,  # .P - data missing due to a prosthesis/knee replacement\n",
    "            \"T\": -1,  # .T - data missing due to technical reasons (e.g. poor image quality)\n",
    "            #.A - data not expected (e.g.: some V00XR...may be missing if participant has KLG<2 in both knees at all time points)\n",
    "            np.nan: -1,\n",
    "        }\n",
    "        df = df.replace({field: dict_fix})\n",
    "\n",
    "    for field in (\"XROSFL\", \"XROSFM\", \"XROSTL\", \"XROSTM\",\n",
    "                  \"XRJSL\", \"XRJSM\",\n",
    "                  \"XRSCFL\", \"XRSCFM\", \"XRSCTL\", \"XRSCTM\",\n",
    "                  \"XRATTL\", \"XRATTM\"):\n",
    "        dict_fix = {\"P\": -1, \"T\": -1, \"A\": -1, \"M\": -1, np.nan: -1}\n",
    "        df = df.replace({field: dict_fix})\n",
    "\n",
    "    fields = (\"XRKL\",\n",
    "              \"XROSFL\", \"XROSFM\", \"XROSTL\", \"XROSTM\",\n",
    "              \"XRSCFL\", \"XRSCFM\", \"XRSCTL\", \"XRSCTM\",\n",
    "              \"XRATTL\", \"XRATTM\")\n",
    "    df = df.astype({f: int for f in fields})\n",
    "\n",
    "    fields = (\"XRJSL\", \"XRJSM\")\n",
    "    df = df.astype({f: float for f in fields})\n",
    "    \n",
    "    # Keep only one assessments for (subject, knee, follow-up)\n",
    "    df = df.drop_duplicates(subset=[\"patient\", \"side\", \"visit\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "dir_xr_sq = Path(\"ACT:SET_PATH/OAI_CompleteData_SAS_20210719\")\n",
    "paths_xr_sq = sorted(dir_xr_sq.glob(\"kxr_sq_bu??.sas7bdat\"))\n",
    "\n",
    "df_xr_sq = read_compose_xr_sq(paths_xr_sq)\n",
    "\n",
    "df_xr_sq = preproc_xr_sq(df_xr_sq)\n",
    "print(len(df_xr_sq))\n",
    "df_xr_sq.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def read_compose_outcomes(paths):\n",
    "    df = read_compose_asmts(paths)\n",
    "\n",
    "    df.columns = df.columns.str.upper()\n",
    "    df = df.rename(columns={\"ID\": \"patient\", })\n",
    "    \n",
    "    df = df.astype({\"patient\": str})\n",
    "    \n",
    "#     print(df.columns)\n",
    "    sel = [\n",
    "        \"patient\",\n",
    "        \"ELKVSRP\",  # OAI visit follow-up TKR (left knee) self-reported at\n",
    "        \"ERKVSRP\",  # OAI visit follow-up TKR (right knee) self-reported at\n",
    "        \n",
    "        \"ELKXRAF\",  # closest OAI visit with knee XR after follow-up TKR (left knee)\n",
    "        \"ERKXRAF\",  # closest OAI visit with knee XR after follow-up TKR (right knee)\n",
    "        \n",
    "        \"ELKXRPR\",  # closest OAI visit with knee XR prior to follow-up TKR (left knee)\n",
    "        \"ERKXRPR\",  # closest OAI visit with knee XR prior to follow-up TKR (right knee)\n",
    "        \n",
    "        \"ELKBLRP\",  # knee replacement (right knee) seen on baseline OAI XR\n",
    "        \"ERKBLRP\",  # knee replacement (right knee) seen on baseline OAI XR\n",
    "         \n",
    "        \"ELKRPSN\",  # knee replacement (left knee) seen on follow-up OAI XR\n",
    "        \"ERKRPSN\",  # knee replacement (right knee) seen on follow-up OAI XR\n",
    "    ]\n",
    "    df = df.loc[:, sel]\n",
    "    return df\n",
    "\n",
    "\n",
    "def preproc_outcomes(df):\n",
    "    # Harmonize the values and fill the missing\n",
    "    for field in (\"ELKVSRP\", \"ERKVSRP\",\n",
    "                  \"ELKXRAF\", \"ERKXRAF\",\n",
    "                  \"ELKXRPR\", \"ERKXRPR\",\n",
    "                 ):\n",
    "        dict_fix = {\n",
    "            \"0: Baseline\": 0,\n",
    "            \"1: 12-month\": 12,\n",
    "            \"2: 18-month\": 18,\n",
    "            \"3: 24-month\": 24,\n",
    "            \"4: 30-month\": 30,\n",
    "            \"5: 36-month\": 36,\n",
    "            \"6: 48-month\": 48,\n",
    "            \"7: 60-month\": 60,\n",
    "            \"8: 72-month\": 72,\n",
    "            \"9: 84-month\": 84,\n",
    "            \"10: 96-month\": 96,\n",
    "            \"11: 108-month\": 108,\n",
    "            '.: Missing Form/Incomplete Workbook': -1,\n",
    "            np.nan: -1, ' ': -1,\n",
    "        }\n",
    "        df = df.fillna({field: -1}, axis=0)\n",
    "        df = df.replace({field: dict_fix})\n",
    "    \n",
    "    for field in (\"ELKBLRP\", \"ERKBLRP\"):\n",
    "        dict_fix = {\n",
    "            \"0: No\": 0,\n",
    "            \"1: Yes\": 1,            \n",
    "            '.: Missing Form/Incomplete Workbook': -1,\n",
    "        }\n",
    "        df = df.fillna({field: -1}, axis=0)\n",
    "        df = df.replace({field: dict_fix})\n",
    "    \n",
    "    for field in (\"ELKRPSN\", \"ERKRPSN\"):\n",
    "        dict_fix = {\n",
    "            '.: Missing Form/Incomplete Workbook': -1,\n",
    "            '0: No replacement seen on any FU xray': 0,\n",
    "            '1: Yes, replacement seen on FU xray': 1,\n",
    "            '2: No FU xrays of this knee (or hip)': 2,\n",
    "        }\n",
    "        df = df.fillna({field: -1}, axis=0)\n",
    "        df = df.replace({field: dict_fix})\n",
    "        \n",
    "    # Melt \"side\"-specific columns\n",
    "    df = pd.concat([df.assign(**{\"side\": \"LEFT\"}),\n",
    "                    df.assign(**{\"side\": \"RIGHT\"})],\n",
    "                    axis=\"index\",\n",
    "                    ignore_index=True)\n",
    "\n",
    "    for f_left, f_right, f_out in [\n",
    "        (\"ELKVSRP\", \"ERKVSRP\", \"E-KVSRP\"),\n",
    "        (\"ELKXRAF\", \"ERKXRAF\", \"E-KXRAF\"),\n",
    "        (\"ELKXRPR\", \"ERKXRPR\", \"E-KXRPR\"),\n",
    "#         (\"ELKTLPR\", \"ERKTLPR\", \"E-KTLPR\"),\n",
    "        (\"ELKBLRP\", \"ERKBLRP\", \"E-KBLRP\"),\n",
    "        (\"ELKRPSN\", \"ERKRPSN\", \"E-KRPSN\"),\n",
    "    ]:\n",
    "        df = df.assign(**{f_out: \"\"})\n",
    "\n",
    "        df.loc[df[\"side\"] == \"LEFT\", f_out] = df[f_left]\n",
    "        df.loc[df[\"side\"] == \"RIGHT\", f_out] = df[f_right]\n",
    "\n",
    "        df = df.astype({f_out: df[f_left].dtype})\n",
    "        df = df.drop(columns=[f_left, f_right])\n",
    "    # ---\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "dir_outcomes = Path(\"ACT:SET_PATH/OAI_CompleteData_ASCII\")\n",
    "paths_outcomes = sorted(dir_outcomes.glob(\"Outcomes99.txt\"))\n",
    "\n",
    "df_outcomes = read_compose_outcomes(paths_outcomes)\n",
    "\n",
    "df_outcomes = preproc_outcomes(df_outcomes)\n",
    "print(len(df_outcomes))\n",
    "df_outcomes.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Read the target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def read_preproc_tiulpin2019(path):\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    df = df.rename(columns={\"ID\": \"patient\",\n",
    "                            \"Side\": \"side\",\n",
    "                            \"Prog_increase\": \"tiulpin2019_kl_diff\",\n",
    "                            \"Progressor\": \"tiulpin2019_prog\"})\n",
    "\n",
    "    df = df.astype({\"patient\": str})\n",
    "    \n",
    "    for field in (\"side\",):\n",
    "        dict_fix = {\n",
    "            \"L\": \"LEFT\",\n",
    "            \"R\": \"RIGHT\",\n",
    "        }\n",
    "        df = df.replace({field: dict_fix})\n",
    "\n",
    "    df[\"visit\"] = 0\n",
    "    # ---\n",
    "    sel = [\"patient\", \"side\", \"visit\", \"tiulpin2019_kl_diff\", \"tiulpin2019_prog\"]\n",
    "    df = df.loc[:, sel]\n",
    "    return df\n",
    "\n",
    "path_tiulpin2019 = Path(\"ACT:SET_PATH/tiulpin2019multimodal__labels.csv\")\n",
    "\n",
    "df_tiulpin2019 = read_preproc_tiulpin2019(path_tiulpin2019)\n",
    "\n",
    "print(len(df_tiulpin2019))\n",
    "df_tiulpin2019.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Merge the meta info"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Records _enrollees: {len(df_enrollees)}\")\n",
    "print(f\"Records _clinical: {len(df_clinical)}\")\n",
    "print(f\"Records _xr_sq: {len(df_xr_sq)}\")\n",
    "print(f\"Records _outcomes: {len(df_outcomes)}\")\n",
    "print()\n",
    "\n",
    "df_t = df_enrollees.copy()\n",
    "t_num_uniq_pat = len(df_t.drop_duplicates(subset=[\"patient\",]))\n",
    "print(f\"Records merge (+enrollees): {len(df_t)}, \"\n",
    "      f\"subjects: {t_num_uniq_pat}\")\n",
    "\n",
    "df_t = df_t.merge(df_clinical,\n",
    "                  on=\"patient\",\n",
    "                  how=\"inner\")\n",
    "t_num_uniq_pat = len(df_t.drop_duplicates(subset=[\"patient\",]))\n",
    "t_num_uniq_knees = len(df_t.drop_duplicates(subset=[\"patient\", \"side\"]))\n",
    "print(f\"Records merge (+clinical): {len(df_t)}, \"\n",
    "      f\"subjects: {t_num_uniq_pat}, knees: {t_num_uniq_knees}\")\n",
    "\n",
    "df_t = df_t.merge(df_xr_sq,\n",
    "                  on=[\"patient\", \"side\", \"visit\", \"visit_month\", \"PREFIX_VAR\"],\n",
    "                  how=\"inner\")\n",
    "t_num_uniq_pat = len(df_t.drop_duplicates(subset=[\"patient\",]))\n",
    "t_num_uniq_knees = len(df_t.drop_duplicates(subset=[\"patient\", \"side\"]))\n",
    "print(f\"Records merge (+xr_sq): {len(df_t)}, \"\n",
    "      f\"subjects: {t_num_uniq_pat}, knees: {t_num_uniq_knees}\")\n",
    "\n",
    "df_t = df_t.merge(df_outcomes,\n",
    "                  on=[\"patient\", \"side\"],\n",
    "                  how=\"left\")\n",
    "t_num_uniq_pat = len(df_t.drop_duplicates(subset=[\"patient\",]))\n",
    "t_num_uniq_knees = len(df_t.drop_duplicates(subset=[\"patient\", \"side\"]))\n",
    "print(f\"Records merge (+outcomes): {len(df_t)}, \"\n",
    "      f\"subjects: {t_num_uniq_pat}, knees: {t_num_uniq_knees}\")\n",
    "\n",
    "df_merge = df_t\n",
    "display(df_merge.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Merge in prior art\n",
    "print(f\"Records _merge: {len(df_merge)}\")\n",
    "print(f\"Records _tiulpin2019: {len(df_tiulpin2019)}\")\n",
    "print()\n",
    "\n",
    "df_t = df_merge.copy()\n",
    "print(f\"Records merge: {len(df_t)}, \"\n",
    "      f\"subjects: {len(pd.unique(df_t['patient']))}\")\n",
    "\n",
    "df_t = df_t.merge(df_tiulpin2019,\n",
    "                  on=[\"patient\", \"side\", \"visit\"],\n",
    "                  how=\"left\",\n",
    "                  indicator=\"tiulpin2019_sel\")\n",
    "dict_fix = {\"both\": 1, \"left_only\": 0}  # omitted due to `left` merge - \"right_only\": 1, \n",
    "df_t = df_t.replace({\"tiulpin2019_sel\": dict_fix})\n",
    "print(f\"Records merge (+tiulpin2019): {len(df_t)}, \"\n",
    "      f\"subjects: {len(pd.unique(df_t['patient']))}\")\n",
    "\n",
    "# Fill missing with -1 to ease downstream processing\n",
    "for field in (\n",
    "    \"tiulpin2019_kl_diff\", \"tiulpin2019_prog\",\n",
    "):\n",
    "    df_t = df_t.replace({field: {\" \": -1, np.nan: -1}})\n",
    "    df_t = df_t.fillna({field: -1}, axis=0)\n",
    "    df_t = df_t.astype({field: int})\n",
    "\n",
    "df_merge = df_t\n",
    "display(df_merge.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save meta to file\n",
    "path_out = \"ACT:SET_PATH/meta_base_clin.csv\"\n",
    "df_merge.to_csv(path_out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Build MR imaging index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Select the scans to be copied\n",
    "\n",
    "df_t_asmts = df_merge.copy()\n",
    "df_t_imgs = df_contents_proc.copy()\n",
    "\n",
    "def print_selection_stats(df):\n",
    "    print(\"Records: \", len(df), \", \",\n",
    "          \"knees: \", len(df.drop_duplicates(subset=[\"patient\", \"side\"])), \", \",\n",
    "          \"subjects: \", len(pd.unique(df[\"patient\"])))\n",
    "\n",
    "print(\"Clinical / assessments:\")\n",
    "print_selection_stats(df_t_asmts)\n",
    "# - Only the baseline scans\n",
    "df_t_asmts = df_t_asmts[df_t_asmts[\"visit\"] == 0]\n",
    "print_selection_stats(df_t_asmts)\n",
    "\n",
    "print(\"Imaging:\")\n",
    "df_t_imgs = df_t_imgs.sort_values(by=[\"patient\", \"side\", \"visit\", \"sequence\"])\n",
    "print_selection_stats(df_t_imgs)\n",
    "\n",
    "# - Only the baseline scans\n",
    "print(\"Only baseline:\")\n",
    "df_t_imgs = df_t_imgs[df_t_imgs[\"visit\"] == 0]\n",
    "print_selection_stats(df_t_imgs)\n",
    "\n",
    "# - Only the following imaging protocols\n",
    "t_sequences = [\n",
    "    \"SAG_3D_DESS\",\n",
    "]\n",
    "df_t_imgs = df_t_imgs[df_t_imgs[\"sequence\"].isin(t_sequences)]\n",
    "print_selection_stats(df_t_imgs)\n",
    "\n",
    "# - In case of rescan, exclude all the previous scans\n",
    "print(\"No rescans:\")\n",
    "df_t_imgs = df_t_imgs.drop_duplicates(\n",
    "    subset=[\"patient\", \"visit\", \"side\", \"sequence\"],\n",
    "    keep=\"last\",\n",
    "    ignore_index=True)\n",
    "print_selection_stats(df_t_imgs)\n",
    "\n",
    "\n",
    "df_extract = df_t_imgs.copy()\n",
    "print_selection_stats(df_extract)\n",
    "\n",
    "# Save to a .csv file\n",
    "path_out = \"ACT:SET_PATH/meta_extract_dess.csv\"\n",
    "df_extract.to_csv(path_out, index=False)\n",
    "display(df_extract)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Extract MR data from the raw OAI"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NUM_SAMPLES_TO_COPY = None\n",
    "# NUM_SAMPLES_TO_COPY = 4\n",
    "\n",
    "SEQUENCES_TO_COPY = [\n",
    "    \"SAG_3D_DESS\",\n",
    "]\n",
    "\n",
    "df_to_copy = df_extract.copy()\n",
    "print(f\"Init, to copy: {len(df_to_copy)}\")\n",
    "\n",
    "# OPTION: Only one sequence to copy\n",
    "df_to_copy = df_to_copy[df_to_copy[\"sequence\"].isin(SEQUENCES_TO_COPY)]\n",
    "\n",
    "# Select number of samples to copy\n",
    "df_to_copy = df_to_copy.iloc[:NUM_SAMPLES_TO_COPY, :]\n",
    "df_to_copy.head()\n",
    "\n",
    "print(f\"Selected, to copy: {len(df_to_copy)}\")\n",
    "display(df_to_copy.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# XR\n",
    "def copy_scans_from_oai(path_root_source, path_root_target, df):\n",
    "    for _, r in tqdm(df.iterrows(), total=len(df)):\n",
    "        path_tmp_from = Path(path_root_source,\n",
    "                             r['visit_month'][1:],\n",
    "                             r['Folder'])\n",
    "        path_tmp_to = Path(path_root_target,\n",
    "                           r['visit_month'][1:],\n",
    "                           r['Folder'])\n",
    "        shutil.copytree(path_tmp_from, path_tmp_to)\n",
    "    \n",
    "_ = copy_scans_from_oai(path_root_source=path_root_source,\n",
    "                        path_root_target=path_root_target,\n",
    "                        df=df_to_copy)\n",
    "\n",
    "df_to_copy.to_csv(Path(path_root_target, 'meta_xr.csv'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# MR\n",
    "def copy_scans_from_oai(path_root_source, path_root_target, df, n_jobs=1, dry_run=False):\n",
    "    def silent_copy(p_from, p_to, dry_run):\n",
    "        if not p_from.exists():\n",
    "            print(f\"Missing: {p_from}\")\n",
    "            return False\n",
    "        else:\n",
    "            if not dry_run:\n",
    "                shutil.copytree(p_from, p_to)\n",
    "            return True\n",
    "        \n",
    "    from joblib import delayed, Parallel\n",
    "    \n",
    "    tasks = []\n",
    "    print(f\"Total: {len(df)}\")\n",
    "    \n",
    "    for _, r in df.iterrows():\n",
    "        path_tmp_from = Path(path_root_source,\n",
    "                             r['visit_month'][1:],\n",
    "                             r['Folder'])\n",
    "        path_tmp_to = Path(path_root_target,\n",
    "                           r['visit_month'][1:],\n",
    "                           r['Folder'])\n",
    "        \n",
    "        tasks.append(delayed(silent_copy)(path_tmp_from, path_tmp_to, dry_run))\n",
    "\n",
    "    ret = Parallel(n_jobs=n_jobs, verbose=5)(t for t in tasks)\n",
    "    # Exclude missing or erroneous data\n",
    "    return df.loc[ret, :]\n",
    "\n",
    "path_root_source = \"ACT:SET_PATH/OAIBaselineImages\"\n",
    "path_root_target = \"ACT:SET_PATH/OAI_SAG_3D_DESS_raw\"\n",
    "os.makedirs(path_root_target, exist_ok=True)\n",
    "\n",
    "df_copied = copy_scans_from_oai(path_root_source=path_root_source,\n",
    "                                path_root_target=path_root_target,\n",
    "                                df=df_to_copy,\n",
    "                                n_jobs=4,\n",
    "#                                 dry_run=True,\n",
    "                               )\n",
    "\n",
    "df_copied.to_csv(Path(path_root_target, 'meta_base_dess.csv'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}